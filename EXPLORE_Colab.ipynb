{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bafanaS/DLC-Object-Recognition-Analysis/blob/master/EXPLORE_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Drive and Initialize Values"
      ],
      "metadata": {
        "id": "RCp3xioDOxHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_name = 'name'\n",
        "\n",
        "label_path = f'/content/drive/MyDrive/.../{project_name}/labeled'\n",
        "training_path = f'/content/drive/MyDrive/.../{project_name}/training'\n",
        "project_path = f'/content/drive/MyDrive/.../{project_name}/'\n",
        "plot_path = f'/content/drive/MyDrive/.../{project_name}/plots'\n",
        "\n",
        "source_dir = f'/content/drive/MyDrive/.../{project_name}/labeled'\n",
        "target_dir = f'/content/drive/MyDrive/.../{project_name}/training'\n",
        "objects = ['ob1', 'ob2']"
      ],
      "metadata": {
        "id": "60Rp3mDxOxNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FvUWjZNs9Zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16ea617f-fb0a-463a-f381-55d66e2aa88f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equalize number of samples in each folder\n",
        "I would not recommend doing this unless the training seems to be faulty each time. Then you can manually adjust the training data with this code."
      ],
      "metadata": {
        "id": "Dd2y_YS9O9BB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1SNxnC_3S3C"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "def get_file_count(folder_path):\n",
        "    return len([f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))])\n",
        "\n",
        "def equalize_folders(folder_paths):\n",
        "    # Get the file counts for each folder\n",
        "    file_counts = [get_file_count(folder) for folder in folder_paths]\n",
        "    min_count = min(file_counts)\n",
        "\n",
        "    # Iterate through each folder and delete files as needed\n",
        "    for folder_path, count in zip(folder_paths, file_counts):\n",
        "        if count > min_count:\n",
        "            # Get all files in the folder\n",
        "            all_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
        "\n",
        "            # Randomly select files to delete\n",
        "            files_to_delete = random.sample(all_files, count - min_count)\n",
        "\n",
        "            # Delete the selected files\n",
        "            for file_name in files_to_delete:\n",
        "                os.remove(os.path.join(folder_path, file_name))\n",
        "                print(f\"Deleted {file_name} from {folder_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg4tBzC83U0E",
        "outputId": "22ef7672-c0c4-4aaf-a7d6-17dbaef4f53d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted no_4959.jpg from /content/drive/MyDrive/Deeplabcut/slr2obj/labeled/no\n",
            "Deleted no_7121.jpg from /content/drive/MyDrive/Deeplabcut/slr2obj/labeled/no\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "folder1 = label_path+'/topnovel'\n",
        "folder2 = label_path+'/botfamiliar'\n",
        "folder3 = label_path+'/no'\n",
        "\n",
        "equalize_folders([folder1, folder2, folder3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create training set"
      ],
      "metadata": {
        "id": "BUXI9IvHPHFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3C4ubx8_oR6A"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "# -------------------------------------------------------------------------------------\n",
        "# ORT analysis - script training data - developed by Victor Ibañez\n",
        "# 03.04.2021\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# import libraries\n",
        "# -----------------------------------------------------\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# create training data\n",
        "# -----------------------------------------------------\n",
        "\n",
        "def create_training_data(source_dir,target_dir,objects):\n",
        "\n",
        "    # iterate through raw data\n",
        "    def collect_candidates(folder_path):\n",
        "\n",
        "        candidates = []\n",
        "\n",
        "        for filename in glob.iglob(folder_path + '/**/*.jpg', recursive=True):\n",
        "            candidates.append(filename)\n",
        "\n",
        "        return candidates\n",
        "\n",
        "    # redesign names and image size\n",
        "    def create_images(candidates, imgsave_path, file_prefix):\n",
        "\n",
        "        cnt = 0\n",
        "        for filename in candidates:\n",
        "            cnt += 1\n",
        "            new_filename = os.path.join(imgsave_path, '{0}_{1}.jpg'.format(file_prefix, cnt))\n",
        "            shutil.copy(filename, new_filename)\n",
        "\n",
        "    # create data randomly and splitting into training, test and validation\n",
        "    def process(source_dir, target_dir, dist_training, dist_validation):\n",
        "\n",
        "        objects.append('no')\n",
        "\n",
        "        distributions = {'training': dist_training, 'validation': dist_validation}\n",
        "\n",
        "        for cls in objects:\n",
        "            candidates = collect_candidates(os.path.join(source_dir, cls))\n",
        "            random.shuffle(candidates)\n",
        "\n",
        "            offset = 0\n",
        "            for key, percentage in distributions.items():\n",
        "\n",
        "                share = math.floor(len(candidates) / 100 * percentage)\n",
        "\n",
        "                class_path = os.path.join(target_dir, key, cls)\n",
        "                if not os.path.isdir(class_path):\n",
        "                    os.makedirs(class_path)\n",
        "\n",
        "                create_images(candidates[offset:offset+share], class_path, cls)\n",
        "                offset += share\n",
        "\n",
        "    process(source_dir,target_dir,80,20)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DzQqFBgazywf"
      },
      "outputs": [],
      "source": [
        "create_training_data(source_dir=source_dir, target_dir=target_dir, objects=objects)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Convolutional Neural Network"
      ],
      "metadata": {
        "id": "AXu3Iu7RPIse"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP7xtQJMoPzD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b6b780-1094-472a-c727-a31c18d6ed18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py:1769: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "# -------------------------------------------------------------------------------------\n",
        "# ORT analysis - script network multi classes - developed by Victor Ibañez\n",
        "# 03.04.2021\n",
        "# -------------------------------------------------------------------------------------\n",
        "\n",
        "# -----------------------------------------------------\n",
        "# import libraries\n",
        "# -----------------------------------------------------\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "import tensorflow as tf\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "sess = tf.compat.v1.InteractiveSession(config=config)\n",
        "\n",
        "def network_multi(source_dir, target_dir, project_path, project_name, plot_path):\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # set directory\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    train_data_dir = os.path.join(target_dir, 'training')\n",
        "    validation_data_dir = os.path.join(target_dir, 'validation')\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # set parameters\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    # extract number of training / validation samples\n",
        "    t = []\n",
        "    v = []\n",
        "    for t_file in glob.iglob(train_data_dir + '/**/*.jpg', recursive=True):\n",
        "        t.append(t_file)\n",
        "    for v_file in glob.iglob(validation_data_dir + '/**/*.jpg', recursive=True):\n",
        "        v.append(v_file)\n",
        "    t_l = len(t)\n",
        "    v_l = len(v)\n",
        "\n",
        "    # extract weights\n",
        "    path = source_dir\n",
        "    classes = os.listdir(path)\n",
        "\n",
        "    cnt_list = []\n",
        "    for cl in classes:\n",
        "        cnt = 0\n",
        "        for i in glob.iglob(os.path.join(path,cl) + '/**/*.jpg', recursive=True):\n",
        "            cnt += 1\n",
        "        cnt_list.append(cnt)\n",
        "\n",
        "    w_list = []\n",
        "    total = sum(cnt_list)\n",
        "    for i in cnt_list:\n",
        "        w_list.append((1 / i)*(total)/len(cnt_list))\n",
        "\n",
        "    weights = {}\n",
        "    for i in range(len(w_list)):\n",
        "        weights[i] = w_list[i]\n",
        "\n",
        "    print('weight distribution among classes:',weights)\n",
        "\n",
        "    # extract image size\n",
        "    print(t)\n",
        "    im = Image.open(t[0])\n",
        "    img_width, img_height = im.size\n",
        "\n",
        "    print('your images are of size: ', img_height, img_width, '3')\n",
        "\n",
        "    epochs = 50\n",
        "    batch_size = 15\n",
        "    if len(classes)==2:\n",
        "        nclasses = 1\n",
        "        loss_type = 'binary_crossentropy'\n",
        "        class_type = 'binary'\n",
        "        activation_fun = 'sigmoid'\n",
        "    else:\n",
        "        nclasses = len(classes)\n",
        "        loss_type = 'categorical_crossentropy'\n",
        "        class_type = 'categorical'\n",
        "        activation_fun = 'softmax'\n",
        "    nb_train_samples = t_l#*nclasses\n",
        "    nb_validation_samples = v_l#*nclasses\n",
        "    learning_rate = 0.00015\n",
        "    dropout_rate = 0.5\n",
        "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
        "                                  patience=3, min_lr=0.000005)\n",
        "    early = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # set input shape of images\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    input_shape = (img_height, img_width, 3)\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # design the CNN\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "# Design the CNN\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(128, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Conv2D(256, (3, 3), activation='relu'),\n",
        "        MaxPooling2D(pool_size=(2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(500, activation='relu'),\n",
        "        Dense(500, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(nclasses, activation=activation_fun)\n",
        "    ])\n",
        "\n",
        "    opt = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss=loss_type, optimizer=opt, metrics=['accuracy'])\n",
        "    callbacks = [early, reduce_lr]\n",
        "\n",
        "    # Image data generators\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "    validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode=class_type)\n",
        "    validation_generator = validation_datagen.flow_from_directory(validation_data_dir, target_size=(img_height, img_width), batch_size=batch_size, class_mode=class_type)\n",
        "\n",
        "    # Train and test the CNN\n",
        "    history = model.fit(train_generator, epochs=epochs, class_weight=weights, callbacks=callbacks, validation_data=validation_generator, validation_steps=nb_validation_samples // batch_size)\n",
        "\n",
        "    # Save the model\n",
        "    project = os.path.join(project_path, project_name)\n",
        "    model.save(os.path.join(project, project_name) + '.h5')\n",
        "\n",
        "    # -----------------------------------------------------\n",
        "    # plot training and validation accuracy & loss values\n",
        "    # -----------------------------------------------------\n",
        "\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    #plt.show()\n",
        "    plt.savefig(os.path.join(plot_path, 'accuracy.png'))\n",
        "    plt.close()\n",
        "\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "    #plt.show()\n",
        "    plt.savefig(os.path.join(plot_path, 'loss.png'))\n",
        "    plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbwSPPVstD5h",
        "outputId": "d1d35a2e-ecd3-4d35-f790-3a99a67a1a8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight distribution among classes: {0: 1.0, 1: 1.0, 2: 1.0}\n",
            "['/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_1.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_2.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_3.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_4.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_5.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_6.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_7.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_8.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_9.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_10.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_11.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_12.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_13.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_14.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_15.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_16.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_17.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_18.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_19.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_20.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_21.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_22.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_23.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_24.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_25.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_26.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_27.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_28.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_29.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_30.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_31.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_32.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_33.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_34.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_35.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_36.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_37.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_38.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_39.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_40.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_41.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_42.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_43.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_44.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_45.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_46.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_47.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_48.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_49.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_50.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_51.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_52.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_53.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_54.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_55.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_56.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_57.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_58.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_59.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_60.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_61.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_62.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_63.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_64.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_65.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_66.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_67.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_68.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_69.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_70.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_71.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_72.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_73.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_74.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_75.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_76.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_77.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_78.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_79.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_80.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_81.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_82.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_83.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_84.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_85.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_86.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_87.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_88.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_89.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_90.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_91.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_92.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_93.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_94.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_95.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_96.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_97.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_98.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_99.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_100.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_101.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_102.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_103.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_104.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_105.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_106.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_107.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_108.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_109.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_110.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_111.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_112.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_113.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_114.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_115.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_116.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_117.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_118.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_119.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_120.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_121.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_122.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_123.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_124.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_125.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_126.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_127.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_128.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_129.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_130.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_131.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_132.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_133.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_134.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_135.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_136.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_137.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_138.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_139.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_140.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_141.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_142.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_143.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_144.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_145.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_146.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_147.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_148.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_149.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_150.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_151.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_152.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_153.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_154.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_155.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_156.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_157.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_158.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_159.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_160.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_161.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_162.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_163.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_164.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_165.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_166.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_167.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_168.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_169.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_170.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_171.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_172.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_173.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_174.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_175.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_176.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_177.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_178.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_179.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/topnovel/topnovel_180.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_1.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_2.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_3.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_4.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_5.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_6.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_7.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_8.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_9.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_10.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_11.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_12.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_13.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_14.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_15.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_16.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_17.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_18.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_19.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_20.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_21.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_22.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_23.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_24.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_25.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_26.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_27.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_28.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_29.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_30.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_31.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_32.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_33.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_34.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_35.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_36.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_37.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_38.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_39.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_40.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_41.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_42.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_43.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_44.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_45.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_46.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_47.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_48.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_49.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_50.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_51.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_52.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_53.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_54.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_55.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_56.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_57.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_58.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_59.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_60.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_61.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_62.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_63.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_64.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_65.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_66.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_67.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_68.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_69.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_70.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_71.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_72.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_73.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_74.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_75.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_76.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_77.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_78.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_79.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_80.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_81.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_82.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_83.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_84.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_85.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_86.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_87.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_88.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_89.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_90.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_91.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_92.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_93.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_94.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_95.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_96.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_97.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_98.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_99.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_100.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_101.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_102.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_103.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_104.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_105.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_106.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_107.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_108.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_109.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_110.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_111.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_112.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_113.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_114.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_115.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_116.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_117.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_118.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_119.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_120.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_121.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_122.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_123.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_124.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_125.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_126.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_127.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_128.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_129.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_130.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_131.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_132.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_133.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_134.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_135.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_136.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_137.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_138.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_139.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_140.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_141.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_142.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_143.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_144.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_145.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_146.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_147.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_148.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_149.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_150.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_151.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_152.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_153.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_154.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_155.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_156.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_157.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_158.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_159.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_160.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_161.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_162.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_163.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_164.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_165.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_166.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_167.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_168.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_169.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_170.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_171.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_172.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_173.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_174.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_175.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_176.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_177.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_178.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_179.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/botfamiliar/botfamiliar_180.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_1.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_2.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_3.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_4.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_5.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_6.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_7.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_8.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_9.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_10.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_11.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_12.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_13.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_14.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_15.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_16.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_17.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_18.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_19.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_20.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_21.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_22.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_23.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_24.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_25.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_26.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_27.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_28.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_29.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_30.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_31.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_32.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_33.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_34.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_35.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_36.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_37.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_38.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_39.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_40.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_41.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_42.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_43.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_44.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_45.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_46.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_47.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_48.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_49.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_50.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_51.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_52.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_53.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_54.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_55.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_56.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_57.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_58.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_59.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_60.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_61.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_62.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_63.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_64.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_65.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_66.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_67.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_68.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_69.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_70.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_71.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_72.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_73.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_74.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_75.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_76.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_77.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_78.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_79.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_80.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_81.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_82.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_83.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_84.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_85.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_86.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_87.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_88.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_89.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_90.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_91.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_92.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_93.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_94.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_95.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_96.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_97.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_98.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_99.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_100.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_101.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_102.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_103.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_104.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_105.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_106.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_107.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_108.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_109.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_110.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_111.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_112.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_113.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_114.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_115.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_116.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_117.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_118.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_119.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_120.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_121.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_122.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_123.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_124.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_125.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_126.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_127.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_128.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_129.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_130.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_131.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_132.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_133.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_134.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_135.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_136.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_137.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_138.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_139.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_140.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_141.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_142.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_143.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_144.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_145.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_146.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_147.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_148.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_149.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_150.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_151.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_152.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_153.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_154.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_155.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_156.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_157.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_158.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_159.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_160.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_161.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_162.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_163.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_164.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_165.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_166.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_167.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_168.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_169.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_170.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_171.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_172.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_173.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_174.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_175.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_176.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_177.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_178.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_179.jpg', '/content/drive/MyDrive/Deeplabcut/slr2obj/training/training/no/no_180.jpg']\n",
            "your images are of size:  150 150 3\n",
            "Found 540 images belonging to 3 classes.\n",
            "Found 135 images belonging to 3 classes.\n",
            "Epoch 1/50\n",
            "36/36 [==============================] - 4s 40ms/step - loss: 1.0966 - accuracy: 0.3648 - val_loss: 1.0468 - val_accuracy: 0.5704 - lr: 1.5000e-04\n",
            "Epoch 2/50\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 0.7020 - accuracy: 0.7389 - val_loss: 0.2968 - val_accuracy: 0.9111 - lr: 1.5000e-04\n",
            "Epoch 3/50\n",
            "36/36 [==============================] - 1s 40ms/step - loss: 0.3524 - accuracy: 0.8778 - val_loss: 0.1843 - val_accuracy: 0.9333 - lr: 1.5000e-04\n",
            "Epoch 4/50\n",
            "36/36 [==============================] - 1s 35ms/step - loss: 0.3273 - accuracy: 0.8833 - val_loss: 0.1960 - val_accuracy: 0.9630 - lr: 1.5000e-04\n",
            "Epoch 5/50\n",
            "36/36 [==============================] - 1s 35ms/step - loss: 0.2309 - accuracy: 0.9315 - val_loss: 0.1690 - val_accuracy: 0.9333 - lr: 1.5000e-04\n",
            "Epoch 6/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.1980 - accuracy: 0.9370 - val_loss: 0.1185 - val_accuracy: 0.9630 - lr: 1.5000e-04\n",
            "Epoch 7/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.2143 - accuracy: 0.9278 - val_loss: 0.1593 - val_accuracy: 0.9481 - lr: 1.5000e-04\n",
            "Epoch 8/50\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.1731 - accuracy: 0.9389 - val_loss: 0.1589 - val_accuracy: 0.9556 - lr: 1.5000e-04\n",
            "Epoch 9/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.1783 - accuracy: 0.9389 - val_loss: 0.1204 - val_accuracy: 0.9778 - lr: 1.5000e-04\n",
            "Epoch 10/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.1352 - accuracy: 0.9574 - val_loss: 0.1109 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 11/50\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 0.1200 - accuracy: 0.9593 - val_loss: 0.1058 - val_accuracy: 0.9704 - lr: 3.0000e-05\n",
            "Epoch 12/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.1242 - accuracy: 0.9574 - val_loss: 0.1058 - val_accuracy: 0.9630 - lr: 3.0000e-05\n",
            "Epoch 13/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.1084 - accuracy: 0.9704 - val_loss: 0.1019 - val_accuracy: 0.9704 - lr: 3.0000e-05\n",
            "Epoch 14/50\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.1148 - accuracy: 0.9685 - val_loss: 0.0975 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 15/50\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.1111 - accuracy: 0.9722 - val_loss: 0.0915 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 16/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.1052 - accuracy: 0.9704 - val_loss: 0.0897 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 17/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.0938 - accuracy: 0.9722 - val_loss: 0.0914 - val_accuracy: 0.9704 - lr: 3.0000e-05\n",
            "Epoch 18/50\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.1076 - accuracy: 0.9704 - val_loss: 0.0880 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 19/50\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0946 - accuracy: 0.9667 - val_loss: 0.0886 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 20/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.0945 - accuracy: 0.9722 - val_loss: 0.0936 - val_accuracy: 0.9704 - lr: 3.0000e-05\n",
            "Epoch 21/50\n",
            "36/36 [==============================] - 1s 35ms/step - loss: 0.0831 - accuracy: 0.9778 - val_loss: 0.0817 - val_accuracy: 0.9852 - lr: 3.0000e-05\n",
            "Epoch 22/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0848 - accuracy: 0.9741 - val_loss: 0.0855 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 23/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0833 - accuracy: 0.9741 - val_loss: 0.0822 - val_accuracy: 0.9778 - lr: 3.0000e-05\n",
            "Epoch 24/50\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.0796 - accuracy: 0.9759 - val_loss: 0.0863 - val_accuracy: 0.9704 - lr: 3.0000e-05\n",
            "Epoch 25/50\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.0887 - accuracy: 0.9704 - val_loss: 0.0802 - val_accuracy: 0.9704 - lr: 6.0000e-06\n",
            "Epoch 26/50\n",
            "36/36 [==============================] - 1s 39ms/step - loss: 0.0804 - accuracy: 0.9704 - val_loss: 0.0802 - val_accuracy: 0.9778 - lr: 6.0000e-06\n",
            "Epoch 27/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.0773 - accuracy: 0.9815 - val_loss: 0.0832 - val_accuracy: 0.9778 - lr: 6.0000e-06\n",
            "Epoch 28/50\n",
            "36/36 [==============================] - 2s 43ms/step - loss: 0.0640 - accuracy: 0.9833 - val_loss: 0.0824 - val_accuracy: 0.9778 - lr: 6.0000e-06\n",
            "Epoch 29/50\n",
            "36/36 [==============================] - 1s 41ms/step - loss: 0.0734 - accuracy: 0.9741 - val_loss: 0.0802 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 30/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0721 - accuracy: 0.9759 - val_loss: 0.0815 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 31/50\n",
            "36/36 [==============================] - 1s 38ms/step - loss: 0.0846 - accuracy: 0.9704 - val_loss: 0.0844 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 32/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0707 - accuracy: 0.9796 - val_loss: 0.0803 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 33/50\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.0657 - accuracy: 0.9796 - val_loss: 0.0807 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 34/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0690 - accuracy: 0.9778 - val_loss: 0.0795 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 35/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0743 - accuracy: 0.9759 - val_loss: 0.0818 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 36/50\n",
            "36/36 [==============================] - 1s 37ms/step - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.0809 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 37/50\n",
            "36/36 [==============================] - 2s 42ms/step - loss: 0.0703 - accuracy: 0.9778 - val_loss: 0.0805 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 38/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0583 - accuracy: 0.9833 - val_loss: 0.0821 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 39/50\n",
            "36/36 [==============================] - 1s 36ms/step - loss: 0.0747 - accuracy: 0.9722 - val_loss: 0.0810 - val_accuracy: 0.9778 - lr: 5.0000e-06\n",
            "Epoch 39: early stopping\n"
          ]
        }
      ],
      "source": [
        "# label_path = '/content/drive/MyDrive/Deeplabcut/nortest/labeled'\n",
        "# training_path = '/content/drive/MyDrive/Deeplabcut/nortest/training'\n",
        "# project_path = '/content/drive/MyDrive/Deeplabcut/nortest/'\n",
        "# project_name = 'nortest'\n",
        "# plot_path = '/content/drive/MyDrive/Deeplabcut/nortest/plots'\n",
        "\n",
        "\n",
        "\n",
        "network_multi(label_path, training_path, project_path, project_name, plot_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on future videos"
      ],
      "metadata": {
        "id": "c0FDmRzcPNtx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcnPXIRUWWLB"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import os, glob\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "# # Configure GPU options\n",
        "# physical_devices = tf.config.list_physical_devices('GPU')\n",
        "# if physical_devices:\n",
        "#     tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# On mac you need to shut this down\n",
        "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
        "\n",
        "def predict_frames_multi(project_path, model, videos, time, ref_point, names, objects, bins, o_coord):\n",
        "    # import model\n",
        "    project_name = os.path.basename(project_path)\n",
        "    loaded_model = tf.keras.models.load_model(model)\n",
        "\n",
        "    data = []\n",
        "    names.append('no')\n",
        "    names.sort()\n",
        "    index = names.index('no')\n",
        "    color_list_fill = [(255,102,255),(102,255,102),(102,255,255),(102,102,255),(107,178,255),(255,102,102)]\n",
        "    color_list_box = [(255,0,255),(0,255,0),(0,255,255),(0,0,255),(0,128,255),(255,0,0)]\n",
        "\n",
        "    # import video\n",
        "    def frame_prediction(video, time, vid_name, ref_point):\n",
        "        vidcap = cv2.VideoCapture(video)\n",
        "        success, frame = vidcap.read()\n",
        "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        count = 1\n",
        "        max_time = (int(time)*60*int(fps))+15\n",
        "\n",
        "        freq_list = []\n",
        "        cnt_list = []\n",
        "        create_list = []\n",
        "        image_list = []\n",
        "\n",
        "        for i in range(len(names)):\n",
        "            cnt_list.append(0)\n",
        "            freq_list.append(0)\n",
        "\n",
        "        while success:\n",
        "            if count > 15 and count < max_time:\n",
        "                res1 = frame[ref_point[0][1]:ref_point[1][1], ref_point[0][0]:ref_point[1][0]]\n",
        "                res = cv2.resize(res1, dsize=(150, 150), interpolation=cv2.INTER_CUBIC)\n",
        "                i = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
        "                i = i/255.\n",
        "                image_list.append(i)\n",
        "                res_gray = cv2.cvtColor(res1, cv2.COLOR_BGR2GRAY)\n",
        "                res_col = cv2.cvtColor(res_gray, cv2.COLOR_GRAY2BGR)\n",
        "                create_list.append(res_col)\n",
        "            elif count >= max_time:\n",
        "                break\n",
        "\n",
        "            success, frame = vidcap.read()\n",
        "            count += 1\n",
        "\n",
        "        img_array = np.array(image_list)\n",
        "        result_proba = loaded_model.predict(img_array)\n",
        "        result = np.argmax(result_proba, axis=1)\n",
        "\n",
        "        cnt_min = 1\n",
        "        for i in range(len(result)):\n",
        "            if i > 0 and result[i] != index and result[i] != result[i-1]:\n",
        "                freq_list[int(result[i])] += 1\n",
        "\n",
        "            prob_result = result_proba[i][result[i]] if len(names) > 2 else result_proba[i][0]\n",
        "\n",
        "            if result[i] != index and prob_result > 0.99:\n",
        "                cnt_list[int(result[i])] += 1\n",
        "                res_col = create_list[i]\n",
        "                for j in range(len(objects)):\n",
        "                    if objects[j] == names[int(result[i])]:\n",
        "                        overlay = res_col.copy()\n",
        "                        overlay[o_coord[j][0][1]:o_coord[j][1][1], o_coord[j][0][0]:o_coord[j][1][0]] = color_list_fill[j]\n",
        "                        o = cv2.addWeighted(overlay,0.5,res_col,0.5,0)\n",
        "                        res_col = o\n",
        "                        cv2.rectangle(res_col, (o_coord[j][0][0], o_coord[j][0][1]), (o_coord[j][1][0], o_coord[j][1][1]), color_list_box[j], thickness=2)\n",
        "                cv2.putText(res_col, names[int(result[i])], (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 3, cv2.LINE_AA, False)\n",
        "                create_list[i] = res_col\n",
        "\n",
        "            if (i+2) % (int(fps)*60*int(bins)) == 0:\n",
        "                d = {'experiment':os.path.basename(os.path.dirname(videos[0])), 'animal':vid_name, 'minute':cnt_min*int(bins)}\n",
        "                for j in range(len(names)):\n",
        "                    if j == index:\n",
        "                        continue\n",
        "                    else:\n",
        "                        d[names[j]] = cnt_list[j]/int(fps)\n",
        "                        d[names[j]+'_freq'] = freq_list[j]\n",
        "                print('minute:', cnt_min*int(bins))\n",
        "                data.append(d)\n",
        "                print(d)\n",
        "                cnt_min += 1\n",
        "                cnt_list = [0] * len(cnt_list)\n",
        "                freq_list = [0] * len(freq_list)\n",
        "\n",
        "        height, width, layers = create_list[0].shape\n",
        "        size = (width, height)\n",
        "        name = os.path.join(project_path, 'prediction_videos', vid_name)\n",
        "        out = cv2.VideoWriter(name + '.MP4', cv2.VideoWriter_fourcc(*'MP4V'), 25, size)\n",
        "        for i in create_list:\n",
        "            out.write(i)\n",
        "        out.release()\n",
        "\n",
        "        print('Done!', count, 'frames predicted from video:', video)\n",
        "\n",
        "    print('start predicting...')\n",
        "    for video in videos:\n",
        "        split = video.split('.')\n",
        "        vid_name = os.path.basename(split[0])\n",
        "        print('processing video:', vid_name)\n",
        "        frame_prediction(video, time, vid_name, ref_point)\n",
        "\n",
        "    print('all videos processed!')\n",
        "    exp_name = os.path.join(project_path, project_name)\n",
        "    df = pd.DataFrame.from_dict(data)\n",
        "    filename = exp_name + '.csv'\n",
        "    if os.path.isfile(filename):\n",
        "        cnt = 1\n",
        "        while True:\n",
        "            new_filename = exp_name + '_' + str(cnt) + '.csv'\n",
        "            cnt += 1\n",
        "            if os.path.isfile(new_filename):\n",
        "                continue\n",
        "            else:\n",
        "                filename = new_filename\n",
        "                break\n",
        "    df.to_csv(filename, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define parameters:"
      ],
      "metadata": {
        "id": "RqqYj8ZnPQuN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq7lNnY6WXh7"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "\n",
        "#predict_frames_multi(project_path, model, videos, time, ref_point, names, objects, bins, o_coord)\n",
        "project_name = 'name' # project name\n",
        "\n",
        "label_path = f'/content/drive/MyDrive/.../{project_name}/labeled'\n",
        "training_path = f'/content/drive/MyDrive/.../{project_name}/training'\n",
        "project_path = f'/content/drive/MyDrive/.../{project_name}/'\n",
        "plot_path = f'/content/drive/MyDrive/.../{project_name}/plots'\n",
        "\n",
        "model = f'/content/drive/MyDrive/.../{project_name}/{project_name}/{project_name}.h5'\n",
        "\n",
        "time = 10 # time of one video\n",
        "\n",
        "bins = 10 # time per one instance of recording object exploration\n",
        "\n",
        "log = open(os.path.join(project_path,\"logfile\"),\"r\")\n",
        "file=log.readlines()\n",
        "ref_point = ast.literal_eval(file[10])\n",
        "coord = ast.literal_eval(file[13])\n",
        "obj_key = ast.literal_eval(file[16])\n",
        "dic = ast.literal_eval(file[22])\n",
        "log.close()\n",
        "\n",
        "names = list(dic.keys())\n",
        "objects = list(obj_key.keys())\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FZfpNNhceBV"
      },
      "outputs": [],
      "source": [
        "videos = [] # The video locations that you want to predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZQ7SVDIYXmC",
        "outputId": "6c23ad88-838f-4652-debe-f07d74027d7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start predicting...\n",
            "processing video: Test 17\n",
            "263/263 [==============================] - 10s 5ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 17', 'minute': 10, 'botfamiliar': 5.214285714285714, 'botfamiliar_freq': 4, 'topnovel': 2.857142857142857, 'topnovel_freq': 31}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 17.mp4\n",
            "processing video: Test 18\n",
            "282/282 [==============================] - 1s 5ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 18', 'minute': 10, 'botfamiliar': 6.0, 'botfamiliar_freq': 29, 'topnovel': 13.8, 'topnovel_freq': 21}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 18.mp4\n",
            "processing video: Test 19\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 19', 'minute': 10, 'botfamiliar': 33.333333333333336, 'botfamiliar_freq': 67, 'topnovel': 12.133333333333333, 'topnovel_freq': 31}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 19.mp4\n",
            "processing video: Test 20\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 20', 'minute': 10, 'botfamiliar': 29.333333333333332, 'botfamiliar_freq': 23, 'topnovel': 31.733333333333334, 'topnovel_freq': 55}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 20.mp4\n",
            "processing video: Test 21\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 21', 'minute': 10, 'botfamiliar': 9.0, 'botfamiliar_freq': 16, 'topnovel': 14.785714285714286, 'topnovel_freq': 29}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 21.mp4\n",
            "processing video: Test 22\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 22', 'minute': 10, 'botfamiliar': 22.333333333333332, 'botfamiliar_freq': 62, 'topnovel': 11.6, 'topnovel_freq': 44}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 22.mp4\n",
            "processing video: Test 23\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 23', 'minute': 10, 'botfamiliar': 3.3333333333333335, 'botfamiliar_freq': 47, 'topnovel': 8.8, 'topnovel_freq': 79}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 23.mp4\n",
            "processing video: Test 24\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 24', 'minute': 10, 'botfamiliar': 11.6, 'botfamiliar_freq': 34, 'topnovel': 39.2, 'topnovel_freq': 32}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-02 - SLR - COHORT 1/Test 24.mp4\n",
            "processing video: Test 31\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 31', 'minute': 10, 'botfamiliar': 13.2, 'botfamiliar_freq': 29, 'topnovel': 6.4, 'topnovel_freq': 32}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 31.mp4\n",
            "processing video: Test 32\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 32', 'minute': 10, 'botfamiliar': 16.285714285714285, 'botfamiliar_freq': 22, 'topnovel': 17.142857142857142, 'topnovel_freq': 22}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 32.mp4\n",
            "processing video: Test 33\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 33', 'minute': 10, 'botfamiliar': 15.533333333333333, 'botfamiliar_freq': 30, 'topnovel': 26.6, 'topnovel_freq': 38}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 33.mp4\n",
            "processing video: Test 34\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 34', 'minute': 10, 'botfamiliar': 20.0, 'botfamiliar_freq': 32, 'topnovel': 29.571428571428573, 'topnovel_freq': 35}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 34.mp4\n",
            "processing video: Test 35\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 35', 'minute': 10, 'botfamiliar': 29.6, 'botfamiliar_freq': 42, 'topnovel': 12.333333333333334, 'topnovel_freq': 42}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 35.mp4\n",
            "processing video: Test 36\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 36', 'minute': 10, 'botfamiliar': 13.533333333333333, 'botfamiliar_freq': 11, 'topnovel': 9.066666666666666, 'topnovel_freq': 10}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 36.mp4\n",
            "processing video: Test 37\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 37', 'minute': 10, 'botfamiliar': 31.928571428571427, 'botfamiliar_freq': 19, 'topnovel': 4.285714285714286, 'topnovel_freq': 19}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 37.mp4\n",
            "processing video: Test 38\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 38', 'minute': 10, 'botfamiliar': 14.071428571428571, 'botfamiliar_freq': 20, 'topnovel': 14.071428571428571, 'topnovel_freq': 36}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 38.mp4\n",
            "processing video: Test 39\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 39', 'minute': 10, 'botfamiliar': 27.214285714285715, 'botfamiliar_freq': 35, 'topnovel': 39.142857142857146, 'topnovel_freq': 50}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 39.mp4\n",
            "processing video: Test 40\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 40', 'minute': 10, 'botfamiliar': 11.333333333333334, 'botfamiliar_freq': 28, 'topnovel': 29.266666666666666, 'topnovel_freq': 13}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 40.mp4\n",
            "processing video: Test 41\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 41', 'minute': 10, 'botfamiliar': 39.733333333333334, 'botfamiliar_freq': 15, 'topnovel': 46.266666666666666, 'topnovel_freq': 32}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 41.mp4\n",
            "processing video: Test 42\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 42', 'minute': 10, 'botfamiliar': 11.2, 'botfamiliar_freq': 6, 'topnovel': 15.866666666666667, 'topnovel_freq': 31}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 42.mp4\n",
            "processing video: Test 43\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 43', 'minute': 10, 'botfamiliar': 32.642857142857146, 'botfamiliar_freq': 15, 'topnovel': 14.428571428571429, 'topnovel_freq': 15}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 43.mp4\n",
            "processing video: Test 44\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 44', 'minute': 10, 'botfamiliar': 2.357142857142857, 'botfamiliar_freq': 12, 'topnovel': 24.785714285714285, 'topnovel_freq': 21}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 44.mp4\n",
            "processing video: Test 45\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 45', 'minute': 10, 'botfamiliar': 11.4, 'botfamiliar_freq': 24, 'topnovel': 7.933333333333334, 'topnovel_freq': 21}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-09 - SLR - COHORT 2/Test 45.mp4\n",
            "processing video: Test 25\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 25', 'minute': 10, 'botfamiliar': 8.8, 'botfamiliar_freq': 15, 'topnovel': 23.866666666666667, 'topnovel_freq': 66}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 25.mp4\n",
            "processing video: Test 26\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 26', 'minute': 10, 'botfamiliar': 5.533333333333333, 'botfamiliar_freq': 8, 'topnovel': 1.2666666666666666, 'topnovel_freq': 13}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 26.mp4\n",
            "processing video: Test 27\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 27', 'minute': 10, 'botfamiliar': 17.4, 'botfamiliar_freq': 42, 'topnovel': 18.666666666666668, 'topnovel_freq': 37}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 27.mp4\n",
            "processing video: Test 28\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 28', 'minute': 10, 'botfamiliar': 0.0, 'botfamiliar_freq': 0, 'topnovel': 0.0, 'topnovel_freq': 1}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 28.mp4\n",
            "processing video: Test 29\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 29', 'minute': 10, 'botfamiliar': 59.333333333333336, 'botfamiliar_freq': 30, 'topnovel': 18.0, 'topnovel_freq': 23}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 29.mp4\n",
            "processing video: Test 30\n",
            "282/282 [==============================] - 1s 5ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 30', 'minute': 10, 'botfamiliar': 158.6, 'botfamiliar_freq': 56, 'topnovel': 31.733333333333334, 'topnovel_freq': 26}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 30.mp4\n",
            "processing video: Test 31\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 31', 'minute': 10, 'botfamiliar': 21.666666666666668, 'botfamiliar_freq': 32, 'topnovel': 8.933333333333334, 'topnovel_freq': 15}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 31.mp4\n",
            "processing video: Test 32\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 32', 'minute': 10, 'botfamiliar': 24.785714285714285, 'botfamiliar_freq': 35, 'topnovel': 29.428571428571427, 'topnovel_freq': 36}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 32.mp4\n",
            "processing video: Test 33\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 33', 'minute': 10, 'botfamiliar': 9.0, 'botfamiliar_freq': 9, 'topnovel': 7.466666666666667, 'topnovel_freq': 13}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 33.mp4\n",
            "processing video: Test 34\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 34', 'minute': 10, 'botfamiliar': 2.0, 'botfamiliar_freq': 4, 'topnovel': 8.928571428571429, 'topnovel_freq': 13}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 34.mp4\n",
            "processing video: Test 35\n",
            "263/263 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 35', 'minute': 10, 'botfamiliar': 3.4285714285714284, 'botfamiliar_freq': 13, 'topnovel': 24.857142857142858, 'topnovel_freq': 15}\n",
            "Done! 8415 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 35.mp4\n",
            "processing video: Test 36\n",
            "282/282 [==============================] - 1s 4ms/step\n",
            "minute: 10\n",
            "{'experiment': '2022-02-02 - SLR - COHORT 1', 'animal': 'Test 36', 'minute': 10, 'botfamiliar': 46.333333333333336, 'botfamiliar_freq': 78, 'topnovel': 27.4, 'topnovel_freq': 64}\n",
            "Done! 9015 frames predicted from video: /content/drive/My Drive/Deeplabcut/m-orientation-hussaini lab-2023-07-10/SLR Videos/2022-02-16 - SLR - COHORT 3/Test 36.mp4\n",
            "all videos processed!\n"
          ]
        }
      ],
      "source": [
        "predict_frames_multi(project_path, model, videos, time, ref_point, names, objects, bins, coord)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Quqv_DJuYeaR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN0yGzGLaOjx8VlA929vbp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}